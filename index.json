[{"categories":null,"contents":"","date":"Sep 01","permalink":"https://srivendare.github.io/projects/wondering/","tags":null,"title":"Walks in Toronto"},{"categories":null,"contents":"","date":"Sep 01","permalink":"https://srivendare.github.io/projects/cx_club/","tags":null,"title":"Cx Club"},{"categories":null,"contents":"","date":"Jul 06","permalink":"https://srivendare.github.io/projects/abnormal_purchase/","tags":null,"title":"Abnormal Purchase Segmentation"},{"categories":["Blog","Sharing","Error"],"contents":"","date":"May 23","permalink":"https://srivendare.github.io/post/rebuild_myblog/","tags":null,"title":"Rebuild workflow of my personal blog"},{"categories":["Map","Ditushu","NLP"],"contents":"This article is about some random outcomes for organizing info in a Multi Language Maps.\nThe Original Map Image is in both Russian and Traditional Chinese:\nAfter OCR through free version web tools:\n   ID English Name Chinese Name Russian Name Longitude Latitude Country Belonged To Year of Train Station Built     1 Changchun 长春 Чанчунь 125.323544 43.817071 China 1898   2 Shenyang 沈阳 Шэньян 123.431472 41.805698 China 189   3 Tianjin 天津 Тяньцзинь 117.199500 39.085097 China 1888    After Cleaning to Json Format:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80  [ { \u0026#34;_id\u0026#34;: 13, \u0026#34;title\u0026#34;: \u0026#34;长春\u0026#34;, \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;Point\u0026#34;, \u0026#34;coordinates\u0026#34;: [ 125.323544, 43.817071 ] } }, { \u0026#34;_id\u0026#34;: 14, \u0026#34;title\u0026#34;: \u0026#34;沈阳\u0026#34;, \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;Point\u0026#34;, \u0026#34;coordinates\u0026#34;: [ 123.431472, 41.805698 ] } }, { \u0026#34;_id\u0026#34;: 15, \u0026#34;title\u0026#34;: \u0026#34;天津\u0026#34;, \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;Point\u0026#34;, \u0026#34;coordinates\u0026#34;: [ 117.1995, 39.085097 ] } }, { \u0026#34;_id\u0026#34;: 16, \u0026#34;title\u0026#34;: \u0026#34;北京\u0026#34;, \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;Point\u0026#34;, \u0026#34;coordinates\u0026#34;: [ 116.407396, 39.9042 ] } }, { \u0026#34;_id\u0026#34;: 17, \u0026#34;title\u0026#34;: \u0026#34;鞍山\u0026#34;, \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;Point\u0026#34;, \u0026#34;coordinates\u0026#34;: [ 122.994646, 41.108546 ] } }, { \u0026#34;_id\u0026#34;: 18, \u0026#34;title\u0026#34;: \u0026#34;大连\u0026#34;, \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;Point\u0026#34;, \u0026#34;coordinates\u0026#34;: [ 121.614682, 38.913689 ] } }, { \u0026#34;_id\u0026#34;: 19, \u0026#34;title\u0026#34;: \u0026#34;元山\u0026#34;, \u0026#34;location\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;Point\u0026#34;, \u0026#34;coordinates\u0026#34;: [ 125.754249, 39.160949 ] } } ]   ","date":"May 16","permalink":"https://srivendare.github.io/post/china_eastern_railway/","tags":null,"title":"Organizing Geospatial Data case study on China Eastern Railway"},{"categories":["Neo4j"],"contents":"This repo try extract data from json raw data and build Knowledge graph in Neo4j\nRaw Data Source:\nhttps://github.com/liuhuanyong/QASystemOnMedicalKG/tree/master/data\nCodes:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291  #encoding:utf8 import os import re import json import codecs import threading from py2neo import Graph import pandas as pd import numpy as np from tqdm import tqdm ### Get data Info def print_data_info(data_path): triples = [] i = 0 with open(data_path,\u0026#39;r\u0026#39;,encoding=\u0026#39;utf8\u0026#39;) as f: for line in f.readlines(): data = json.loads(line) print(json.dumps(data, sort_keys=True, indent=4, separators=(\u0026#39;, \u0026#39;, \u0026#39;: \u0026#39;),ensure_ascii=False)) i += 1 if i \u0026gt;=5: break return triples ### Extraction Object class MedicalExtractor(object): def __init__(self): super(MedicalExtractor, self).__init__() self.graph = Graph( host=\u0026#34;127.0.0.1\u0026#34;, http_port=7474, user=\u0026#34;neo4j\u0026#34;, password=\u0026#34;123456\u0026#34;) # 共8类节点 self.drugs = [] # 药品 self.recipes = [] #菜谱 self.foods = [] #　食物 self.checks = [] # 检查 self.departments = [] #科室 self.producers = [] #药企 self.diseases = [] #疾病 self.symptoms = []#症状 self.disease_infos = []#疾病信息 # 构建节点实体关系 self.rels_department = [] #　科室－科室关系 self.rels_noteat = [] # 疾病－忌吃食物关系 self.rels_doeat = [] # 疾病－宜吃食物关系 self.rels_recommandeat = [] # 疾病－推荐吃食物关系 self.rels_commonddrug = [] # 疾病－通用药品关系 self.rels_recommanddrug = [] # 疾病－热门药品关系 self.rels_check = [] # 疾病－检查关系 self.rels_drug_producer = [] # 厂商－药物关系 self.rels_symptom = [] #疾病症状关系 self.rels_acompany = [] # 疾病并发关系 self.rels_category = [] #　疾病与科室之间的关系 def extract_triples(self,data_path): print(\u0026#34;从json文件中转换抽取三元组\u0026#34;) with open(data_path,\u0026#39;r\u0026#39;,encoding=\u0026#39;utf8\u0026#39;) as f: for line in tqdm(f.readlines(),ncols=80): data_json = json.loads(line) disease_dict = {} disease = data_json[\u0026#39;name\u0026#39;] disease_dict[\u0026#39;name\u0026#39;] = disease self.diseases.append(disease) disease_dict[\u0026#39;desc\u0026#39;] = \u0026#39;\u0026#39; disease_dict[\u0026#39;prevent\u0026#39;] = \u0026#39;\u0026#39; disease_dict[\u0026#39;cause\u0026#39;] = \u0026#39;\u0026#39; disease_dict[\u0026#39;easy_get\u0026#39;] = \u0026#39;\u0026#39; disease_dict[\u0026#39;cure_department\u0026#39;] = \u0026#39;\u0026#39; disease_dict[\u0026#39;cure_way\u0026#39;] = \u0026#39;\u0026#39; disease_dict[\u0026#39;cure_lasttime\u0026#39;] = \u0026#39;\u0026#39; disease_dict[\u0026#39;symptom\u0026#39;] = \u0026#39;\u0026#39; disease_dict[\u0026#39;cured_prob\u0026#39;] = \u0026#39;\u0026#39; if \u0026#39;symptom\u0026#39; in data_json: self.symptoms += data_json[\u0026#39;symptom\u0026#39;] for symptom in data_json[\u0026#39;symptom\u0026#39;]: self.rels_symptom.append([disease,\u0026#39;has_symptom\u0026#39;, symptom]) if \u0026#39;acompany\u0026#39; in data_json: for acompany in data_json[\u0026#39;acompany\u0026#39;]: self.rels_acompany.append([disease,\u0026#39;acompany_with\u0026#39;, acompany]) self.diseases.append(acompany) if \u0026#39;desc\u0026#39; in data_json: disease_dict[\u0026#39;desc\u0026#39;] = data_json[\u0026#39;desc\u0026#39;] if \u0026#39;prevent\u0026#39; in data_json: disease_dict[\u0026#39;prevent\u0026#39;] = data_json[\u0026#39;prevent\u0026#39;] if \u0026#39;cause\u0026#39; in data_json: disease_dict[\u0026#39;cause\u0026#39;] = data_json[\u0026#39;cause\u0026#39;] if \u0026#39;get_prob\u0026#39; in data_json: disease_dict[\u0026#39;get_prob\u0026#39;] = data_json[\u0026#39;get_prob\u0026#39;] if \u0026#39;easy_get\u0026#39; in data_json: disease_dict[\u0026#39;easy_get\u0026#39;] = data_json[\u0026#39;easy_get\u0026#39;] if \u0026#39;cure_department\u0026#39; in data_json: cure_department = data_json[\u0026#39;cure_department\u0026#39;] if len(cure_department) == 1: self.rels_category.append([disease, \u0026#39;cure_department\u0026#39;,cure_department[0]]) if len(cure_department) == 2: big = cure_department[0] small = cure_department[1] self.rels_department.append([small,\u0026#39;belongs_to\u0026#39;, big]) self.rels_category.append([disease,\u0026#39;cure_department\u0026#39;, small]) disease_dict[\u0026#39;cure_department\u0026#39;] = cure_department self.departments += cure_department if \u0026#39;cure_way\u0026#39; in data_json: disease_dict[\u0026#39;cure_way\u0026#39;] = data_json[\u0026#39;cure_way\u0026#39;] if \u0026#39;cure_lasttime\u0026#39; in data_json: disease_dict[\u0026#39;cure_lasttime\u0026#39;] = data_json[\u0026#39;cure_lasttime\u0026#39;] if \u0026#39;cured_prob\u0026#39; in data_json: disease_dict[\u0026#39;cured_prob\u0026#39;] = data_json[\u0026#39;cured_prob\u0026#39;] if \u0026#39;common_drug\u0026#39; in data_json: common_drug = data_json[\u0026#39;common_drug\u0026#39;] for drug in common_drug: self.rels_commonddrug.append([disease,\u0026#39;has_common_drug\u0026#39;, drug]) self.drugs += common_drug if \u0026#39;recommand_drug\u0026#39; in data_json: recommand_drug = data_json[\u0026#39;recommand_drug\u0026#39;] self.drugs += recommand_drug for drug in recommand_drug: self.rels_recommanddrug.append([disease,\u0026#39;recommand_drug\u0026#39;, drug]) if \u0026#39;not_eat\u0026#39; in data_json: not_eat = data_json[\u0026#39;not_eat\u0026#39;] for _not in not_eat: self.rels_noteat.append([disease,\u0026#39;not_eat\u0026#39;, _not]) self.foods += not_eat do_eat = data_json[\u0026#39;do_eat\u0026#39;] for _do in do_eat: self.rels_doeat.append([disease,\u0026#39;do_eat\u0026#39;, _do]) self.foods += do_eat if \u0026#39;recommand_eat\u0026#39; in data_json: recommand_eat = data_json[\u0026#39;recommand_eat\u0026#39;] for _recommand in recommand_eat: self.rels_recommandeat.append([disease,\u0026#39;recommand_recipes\u0026#39;, _recommand]) self.recipes += recommand_eat if \u0026#39;check\u0026#39; in data_json: check = data_json[\u0026#39;check\u0026#39;] for _check in check: self.rels_check.append([disease, \u0026#39;need_check\u0026#39;, _check]) self.checks += check if \u0026#39;drug_detail\u0026#39; in data_json: for det in data_json[\u0026#39;drug_detail\u0026#39;]: det_spilt = det.split(\u0026#39;(\u0026#39;) if len(det_spilt) == 2: p,d = det_spilt d = d.rstrip(\u0026#39;)\u0026#39;) if p.find(d) \u0026gt; 0: p = p.rstrip(d) self.producers.append(p) self.drugs.append(d) self.rels_drug_producer.append([p,\u0026#39;production\u0026#39;,d]) else: d = det_spilt[0] self.drugs.append(d) self.disease_infos.append(disease_dict) def write_nodes(self,entitys,entity_type): print(\u0026#34;写入 {0}实体\u0026#34;.format(entity_type)) for node in tqdm(set(entitys),ncols=80): cql = \u0026#34;\u0026#34;\u0026#34;MERGE(n:{label}{{name:\u0026#39;{entity_name}\u0026#39;}})\u0026#34;\u0026#34;\u0026#34;.format( label=entity_type,entity_name=node.replace(\u0026#34;\u0026#39;\u0026#34;,\u0026#34;\u0026#34;)) try: self.graph.run(cql) except Exception as e: print(e) print(cql) def write_edges(self,triples,head_type,tail_type): print(\u0026#34;写入 {0}关系\u0026#34;.format(triples[0][1])) for head,relation,tail in tqdm(triples,ncols=80): cql = \u0026#34;\u0026#34;\u0026#34;MATCH(p:{head_type}),(q:{tail_type}) WHERE p.name=\u0026#39;{head}\u0026#39; AND q.name=\u0026#39;{tail}\u0026#39; MERGE (p)-[r:{relation}]-\u0026gt;(q)\u0026#34;\u0026#34;\u0026#34;.format( head_type=head_type,tail_type=tail_type,head=head.replace(\u0026#34;\u0026#39;\u0026#34;,\u0026#34;\u0026#34;), tail=tail.replace(\u0026#34;\u0026#39;\u0026#34;,\u0026#34;\u0026#34;),relation=relation) try: self.graph.run(cql) except Exception as e: print(e) print(cql) def set_attributes(self,entity_infos,etype): print(\u0026#34;写入 {0}实体的属性\u0026#34;.format(etype)) for e_dict in tqdm(entity_infos[892:],ncols=80): name = e_dict[\u0026#39;name\u0026#39;] del e_dict[\u0026#39;name\u0026#39;] for k,v in e_dict.items(): if k in [\u0026#39;cure_department\u0026#39;,\u0026#39;cure_way\u0026#39;]: cql = \u0026#34;\u0026#34;\u0026#34;MATCH (n:{label}) WHERE n.name=\u0026#39;{name}\u0026#39; set n.{k}={v}\u0026#34;\u0026#34;\u0026#34;.format(label=etype,name=name.replace(\u0026#34;\u0026#39;\u0026#34;,\u0026#34;\u0026#34;),k=k,v=v) else: cql = \u0026#34;\u0026#34;\u0026#34;MATCH (n:{label}) WHERE n.name=\u0026#39;{name}\u0026#39; set n.{k}=\u0026#39;{v}\u0026#39;\u0026#34;\u0026#34;\u0026#34;.format(label=etype,name=name.replace(\u0026#34;\u0026#39;\u0026#34;,\u0026#34;\u0026#34;),k=k,v=v.replace(\u0026#34;\u0026#39;\u0026#34;,\u0026#34;\u0026#34;).replace(\u0026#34;\\n\u0026#34;,\u0026#34;\u0026#34;)) try: self.graph.run(cql) except Exception as e: print(e) print(cql) def create_entitys(self): self.write_nodes(self.drugs,\u0026#39;药品\u0026#39;) self.write_nodes(self.recipes,\u0026#39;菜谱\u0026#39;) self.write_nodes(self.foods,\u0026#39;食物\u0026#39;) self.write_nodes(self.checks,\u0026#39;检查\u0026#39;) self.write_nodes(self.departments,\u0026#39;科室\u0026#39;) self.write_nodes(self.producers,\u0026#39;药企\u0026#39;) self.write_nodes(self.diseases,\u0026#39;疾病\u0026#39;) self.write_nodes(self.symptoms,\u0026#39;症状\u0026#39;) def create_relations(self): self.write_edges(self.rels_department,\u0026#39;科室\u0026#39;,\u0026#39;科室\u0026#39;) self.write_edges(self.rels_noteat,\u0026#39;疾病\u0026#39;,\u0026#39;食物\u0026#39;) self.write_edges(self.rels_doeat,\u0026#39;疾病\u0026#39;,\u0026#39;食物\u0026#39;) self.write_edges(self.rels_recommandeat,\u0026#39;疾病\u0026#39;,\u0026#39;菜谱\u0026#39;) self.write_edges(self.rels_commonddrug,\u0026#39;疾病\u0026#39;,\u0026#39;药品\u0026#39;) self.write_edges(self.rels_recommanddrug,\u0026#39;疾病\u0026#39;,\u0026#39;药品\u0026#39;) self.write_edges(self.rels_check,\u0026#39;疾病\u0026#39;,\u0026#39;检查\u0026#39;) self.write_edges(self.rels_drug_producer,\u0026#39;药企\u0026#39;,\u0026#39;药品\u0026#39;) self.write_edges(self.rels_symptom,\u0026#39;疾病\u0026#39;,\u0026#39;症状\u0026#39;) self.write_edges(self.rels_acompany,\u0026#39;疾病\u0026#39;,\u0026#39;疾病\u0026#39;) self.write_edges(self.rels_category,\u0026#39;疾病\u0026#39;,\u0026#39;科室\u0026#39;) def set_diseases_attributes(self): t=threading.Thread(target=self.set_attributes,args=(self.disease_infos,\u0026#34;疾病\u0026#34;)) t.setDaemon(False) t.start() def export_data(self,data,path): if isinstance(data[0],str): data = sorted([d.strip(\u0026#34;...\u0026#34;) for d in set(data)]) with codecs.open(path, \u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: json.dump(data, f, indent=4, ensure_ascii=False) def export_entitys_relations(self): self.export_data(self.drugs,\u0026#39;./graph_data/drugs.json\u0026#39;) self.export_data(self.recipes,\u0026#39;./graph_data/recipes.json\u0026#39;) self.export_data(self.foods,\u0026#39;./graph_data/foods.json\u0026#39;) self.export_data(self.checks,\u0026#39;./graph_data/checks.json\u0026#39;) self.export_data(self.departments,\u0026#39;./graph_data/departments.json\u0026#39;) self.export_data(self.producers,\u0026#39;./graph_data/producers.json\u0026#39;) self.export_data(self.diseases,\u0026#39;./graph_data/diseases.json\u0026#39;) self.export_data(self.symptoms,\u0026#39;./graph_data/symptoms.json\u0026#39;) self.export_data(self.rels_department,\u0026#39;./graph_data/rels_department.json\u0026#39;) self.export_data(self.rels_noteat,\u0026#39;./graph_data/rels_noteat.json\u0026#39;) self.export_data(self.rels_doeat,\u0026#39;./graph_data/rels_doeat.json\u0026#39;) self.export_data(self.rels_recommandeat,\u0026#39;./graph_data/rels_recommandeat.json\u0026#39;) self.export_data(self.rels_commonddrug,\u0026#39;./graph_data/rels_commonddrug.json\u0026#39;) self.export_data(self.rels_recommanddrug,\u0026#39;./graph_data/rels_recommanddrug.json\u0026#39;) self.export_data(self.rels_check,\u0026#39;./graph_data/rels_check.json\u0026#39;) self.export_data(self.rels_drug_producer,\u0026#39;./graph_data/rels_drug_producer.json\u0026#39;) self.export_data(self.rels_symptom,\u0026#39;./graph_data/rels_symptom.json\u0026#39;) self.export_data(self.rels_acompany,\u0026#39;./graph_data/rels_acompany.json\u0026#39;) self.export_data(self.rels_category,\u0026#39;./graph_data/rels_category.json\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: path = \u0026#34;./graph_data/medical.json\u0026#34; extractor = MedicalExtractor() extractor.extract_triples(path) extractor.export_entitys_relations()   Final Results Demo:\n","date":"Apr 05","permalink":"https://srivendare.github.io/post/building-graphs/","tags":null,"title":"Basic Knowledge Graph in Neo4j"},{"categories":["Golang"],"contents":"2022-03-06\nRecently I need to maintain colleague\u0026rsquo;s web scrapers in Golang, here are some notes I took during self-learning, I will keep on updating this article\n Lorca a tool for connect and communicate with web Serber  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  package main import ( \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;github.com/zserge/lorca\u0026#34; ) func main() { var ui lorca.UI ui, _ = lorca.New(\u0026#34;https://baidu.com\u0026#34;, \u0026#34;\u0026#34;, 800, 600, \u0026#34;--display-sync\u0026#34;, \u0026#34;--display-translate\u0026#34;) chSignal := make(chan os.Signal, 1) signal.Notify(chSignal, syscall.SIGINT, syscall.SIGTERM) select { case \u0026lt;-ui.Done(): case \u0026lt;-chSignal: } // close ui  ui.Close() }   The key point of this code block is event listening,\nthe chrome browser and ui server are in different thread, this listener make all process end if there is one process interrupted or terminated\n1 2 3 4 5  signal.Notify(chSignal, syscall.SIGINT, syscall.SIGTERM) select { case \u0026lt;-ui.Done(): case \u0026lt;-chSignal: }   ","date":"Jan 01","permalink":"https://srivendare.github.io/post/golang_cheatsheet/","tags":null,"title":"Golang Cheatsheet"},{"categories":["pandas, finance"],"contents":"To do multiple tasks with async.map asynchronously you have to:\n Define a function for what you want to do with each object (your task) Add that function as an event hook in your request Call async.map on a list of all the requests / actions  Example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  from requests import async # from grequests import async urls = [ \u0026#39;http://python-requests.org\u0026#39;, \u0026#39;http://httpbin.org\u0026#39;, \u0026#39;http://python-guide.org\u0026#39;, \u0026#39;http://kennethreitz.com\u0026#39; ] # A simple task to do to each response object def do_something(response): print response.url # A list to hold our things to do via async async_list = [] for u in urls: # The \u0026#34;hooks = {...\u0026#34; part is where you define what you want to do #  # Note the lack of parentheses following do_something, this is # because the response will be used as the first argument automatically action_item = async.get(u, hooks = {\u0026#39;response\u0026#39; : do_something}) # Add the task to our list of things to do via async async_list.append(action_item) # Do our list of things to do via async async.map(async_list)   ","date":"Sep 07","permalink":"https://srivendare.github.io/post/async/","tags":null,"title":"An Async Example for API request"},{"categories":["pandas, finance"],"contents":"Due to personal issue, I need to track Forex info recently. However, unlike professional trader, I don\u0026rsquo;t need ticker for every minutes, but day by date is to rough. So this project is a simple pandas manuplation about yfinance API in python, the final aim is to build a FastAPI with ['morning', 'day', 'evening'] avg forex data,\nLet\u0026rsquo;s start by import dependencies:\n1 2 3 4 5 6  # For data manipulation import numpy as np import pandas as pd # To fetch financial data import yfinance as yf   Get the data frame in API\n1 2 3 4 5 6 7 8 9 10  # Set the ticker as \u0026#39;EURUSD=X\u0026#39; forex_data_minute = yf.download(\u0026#39;CADCNY=X\u0026#39;, period=\u0026#39;60d\u0026#39;, interval=\u0026#39;15m\u0026#39;) # Clear the index info with Api forex_data_minute = forex_data_minute.reset_index() # Set date and hour from timestamp in API forex_data_minute[\u0026#39;hour\u0026#39;] = pd.to_datetime(forex_data_minute[\u0026#39;Datetime\u0026#39;]).dt.hour forex_data_minute[\u0026#39;date\u0026#39;] = pd.to_datetime(forex_data_minute[\u0026#39;Datetime\u0026#39;]).dt.date   Next step is the core part, which used pd.cut method to create bins\n1 2 3 4 5 6 7 8 9 10  # Provide bin\u0026amp; lebals info bins = [0, 12, 18, 24] labels = [\u0026#39;Morning\u0026#39;, \u0026#39;Day time\u0026#39;, \u0026#39;Evening\u0026#39;] # Make bin info within dataframe from numpy import average forex_data_minute[\u0026#39;day_time\u0026#39;] = pd.cut(x=forex_data_minute[\u0026#39;hour\u0026#39;], bins= bins, labels=labels, include_lowest =True) # Aggregate final results forex_data_minute.groupby([\u0026#39;date\u0026#39;,\u0026#39;day_time\u0026#39;]).agg({\u0026#39;Adj Close\u0026#39;: average })   Next step make a function for creating a FastAPI \u0026hellip;\n","date":"Jul 20","permalink":"https://srivendare.github.io/post/play_yfinance/","tags":null,"title":"Playing yfinance with Pandas"},{"categories":["Machine Learning","Time Series","Cheatsheet"],"contents":"Judging criteria of machine learning models is always an important concerns in real life projects. This artical aims to provide some basic info for opting varibles for improving and evaluating machine learning models\n","date":"Feb 19","permalink":"https://srivendare.github.io/post/time_series_evaluation/","tags":null,"title":"ML Evaluation Indexes"},{"categories":["Machine Learning","Time Series","Cheatsheet"],"contents":"This article aims to provide some pre-fabricated functions for time series analysis. After a dedication in Time Series field for past few months, I found it is good for getting some structual knowledge recorded.\nThrough extensive projects and refinement, I have crafted a collection of functions that aim to streamline the process of analyzing temporal patterns, identifying trends, and extracting meaningful insights from time series datasets.\nIn real work, I use these function to deliver fast results, although the basic notion can be easily forget sometimes : )\nBasic required libraries:\n1 2 3 4 5 6 7 8 9  # For data manipulation import numpy as np import pandas as pd # To fetch financial data import yfinance as yf # For visualisation import matplotlib.pyplot as plt   Plotting Moving Avg.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  def plotMovingAvg(series, window, scale = 1.96, plot_intervals =False, anomalies = False): \u0026#34;\u0026#34;\u0026#34; series - time indexed dataframe window - rolling window size (days) \u0026#34;\u0026#34;\u0026#34; # by_day_stage = series # by_day_stage[\u0026#39;timestamp\u0026#39;] = series.index # by_day_stage[\u0026#39;date\u0026#39;] = series.apply(lambda x:str(x[\u0026#39;timestamp\u0026#39;]).split()[0], axis=1) # by_day = by_day_stage.groupby(by=\u0026#39;date\u0026#39;).agg({\u0026#39;open\u0026#39;: \u0026#39;mean\u0026#39;}) rolling_mean = series.rolling(window=window).mean() fig, ax = plt.subplots(figsize=(16,9)) ax.plot(series[window:], label=\u0026#34;Actual values\u0026#34;) ax.plot(rolling_mean, label = \u0026#39;MA\u0026#39;) ax.set_title(\u0026#34;Moving average\\nwindow size = {}\u0026#34;.format(window)) # plot intervals if plot_intervals: mae = mean_absolute_error(series[window:], rolling_mean[window:]) deviation = np.std(series[window:] - rolling_mean[window:]) lower_bond = rolling_mean - (mae + scale * deviation) upper_bond = rolling_mean + (mae + scale * deviation) plt.plot(upper_bond, \u0026#34;r--\u0026#34;, label=\u0026#34;Upper Bond / Lower Bond\u0026#34;) plt.plot(lower_bond, \u0026#34;r--\u0026#34;) # plot abnormals # Having the intervals, find abnormal values if anomalies: anomalies = pd.DataFrame(index=series.index, columns=series.columns) anomalies[series\u0026lt;lower_bond] = series[series\u0026lt;lower_bond] anomalies[series\u0026gt;upper_bond] = series[series\u0026gt;upper_bond] plt.plot(anomalies, \u0026#34;ro\u0026#34;, markersize=10)   Example Plotting\n1  plotMovingAvg(test_df, 480, plot_intervals =True, anomalies = True)   Export Results\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  def plotModelResults(model, X_train=X_train, X_test=X_test, plot_intervals=False, plot_anomalies=False): \u0026#34;\u0026#34;\u0026#34; Plots modelled vs fact values, prediction intervals and anomalies \u0026#34;\u0026#34;\u0026#34; prediction = model.predict(X_test plt.figure(figsize=(15, 7)) plt.plot(prediction, \u0026#34;g\u0026#34;, label=\u0026#34;prediction\u0026#34;, linewidth=2.0) plt.plot(y_test.values, label=\u0026#34;actual\u0026#34;, linewidth=2.0) if plot_intervals: cv = cross_val_score(model, X_train, y_train, cv=tscv, scoring=\u0026#34;neg_mean_absolute_error\u0026#34;) mae = cv.mean() * (-1) deviation = cv.std() scale = 1.96 lower = prediction - (mae + scale * deviation) upper = prediction + (mae + scale * deviation) plt.plot(lower, \u0026#34;r--\u0026#34;, label=\u0026#34;upper bond / lower bond\u0026#34;, alpha=0.5) plt.plot(upper, \u0026#34;r--\u0026#34;, alpha=0.5) if plot_anomalies: anomalies = np.array([np.NaN]*len(y_test)) anomalies[y_test\u0026lt;lower] = y_test[y_test\u0026lt;lower] anomalies[y_test\u0026gt;upper] = y_test[y_test\u0026gt;upper] plt.plot(anomalies, \u0026#34;o\u0026#34;, markersize=10, label = \u0026#34;Anomalies\u0026#34;) error = mean_absolute_percentage_error(prediction, y_test) plt.title(\u0026#34;Mean absolute percentage error {0:.2f}%\u0026#34;.format(error)) plt.legend(loc=\u0026#34;best\u0026#34;) plt.tight_layout() plt.grid(True);   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  def plotCoefficients(model): \u0026#34;\u0026#34;\u0026#34; Plots sorted coefficient values of the model \u0026#34;\u0026#34;\u0026#34; coefs = pd.DataFrame(model.coef_, X_train.columns) coefs.columns = [\u0026#34;coef\u0026#34;] coefs[\u0026#34;abs\u0026#34;] = coefs.coef.apply(np.abs) coefs = coefs.sort_values(by=\u0026#34;abs\u0026#34;, ascending=False).drop([\u0026#34;abs\u0026#34;], axis=1) plt.figure(figsize=(15, 7)) coefs.coef.plot(kind=\u0026#39;bar\u0026#39;) plt.grid(True, axis=\u0026#39;y\u0026#39;) plt.hlines(y=0, xmin=0, xmax=len(coefs), linestyles=\u0026#39;dashed\u0026#39;);   XGBoot Codes:\n1 2 3 4 5 6 7 8 9  from xgboost import XGBRegressor xgb = XGBRegressor() xgb.fit(X_train_scaled, y_train) plotModelResults(xgb, X_train=X_train_scaled, X_test=X_test_scaled, plot_intervals=True, plot_anomalies=True)   ","date":"Feb 19","permalink":"https://srivendare.github.io/post/time_series_cheatsheet/","tags":null,"title":"Time Series Cheatsheet"},{"categories":["Knowledge Management","ETL"],"contents":"","date":"Nov 02","permalink":"https://srivendare.github.io/post/extracting_info_from_struactual_data_source/","tags":null,"title":"Extracting Knowledge from Unstructual data"},{"categories":["Machine Learning","NLP"],"contents":"In this article, I tried out Cohere\u0026rsquo;s generative models to extract entities from random texts. It involves employing structured generation, wherein I provided multiple examples within the prompt to enhance the model\u0026rsquo;s ability to generate accurate entity extractions.\n","date":"Oct 05","permalink":"https://srivendare.github.io/post/entitiy_extraction/","tags":null,"title":"Basic NLP of Entity Extraction"},{"categories":["Flask"],"contents":"This ariticle aims to give an idea about how to use plot.ly in Flask App.\nOn the route, pass json to HTML\n1 2 3 4  # Create a plotly chart object fig = px.bar(industry_report , x=\u0026#39;grade\u0026#39;, y=\u0026#39;num\u0026#39;) # Get json from the chart figJson = json.dumps(fig, cls=plotly.utils.PlotlyJSONEncoder)   On the page, get json from python and create chart object\n1 2 3 4  var graphs = {{ figJson | safe }}; Plotly.plot(\u0026#39;chart\u0026#39;,graphs, {});   ","date":"Sep 19","permalink":"https://srivendare.github.io/post/diary_1/","tags":null,"title":"Using Plotly Charts in Flaks"},{"categories":["syntax"],"contents":"Lorem ipsum dolor sit amet1 consectetur adipisicing elit. Nemo tempora eum cumque neque voluptatum, odit ipsum consequatur animi.\nLorem ipsum dolor sit amet consectetur adipisicing elit. Nemo tempora eum cumque neque voluptatum, odit ipsum2 consequatur animi.\nLorem ipsum dolor sit amet consectetur adipisicing elit. Nemo tempora eum cumque neque voluptatum, odit ipsum consequatur animi.\nLorem ipsum dolor sit amet consectetur adipisicing elit. Nemo tempora eum cumque neque voluptatum, odit ipsum consequatur animi.\n  Test Footnote\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n Test Footnote2\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","date":"May 31","permalink":"https://srivendare.github.io/post/footnote/","tags":null,"title":"Footnote test"},{"categories":["math"],"contents":"The following\n$$ \\int_{a}^{b} x^2 dx $$\nIs an integral\n$$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\nEnable Katex in the config file by setting the katex param to true. This will import the necessary Katex CSS/JS.\nSee the online reference of supported TeX functions.\n1  Inline math: $\\varphi=\\dfrac{1+\\sqrt5}{2}=1.6180339887… $   Inline math: $ \\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887… $\n1 2 3  Block math: $$\\varphi=1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$   Block math:\n$$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n","date":"May 22","permalink":"https://srivendare.github.io/post/test-katex/","tags":null,"title":"Katex support"},{"categories":["math"],"contents":"The following\n$$ \\int_{a}^{b} x^2 dx $$\nIs an integral\n$$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\nEnable MathJax in the config file by setting the mathjax param to true. This will import the necessary MathJax CSS/JS.\n1  Inline math: $\\varphi=\\dfrac{1+\\sqrt5}{2}=1.6180339887… $   Inline math: $ \\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887… $\n1 2 3  Block math: $$\\varphi=1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$   Block math:\n$$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$\n","date":"May 22","permalink":"https://srivendare.github.io/post/test-mathjax/","tags":null,"title":"MathJax support"},{"categories":["themes","syntax"],"contents":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\n   Headings  The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\n   H1     H2     H3     H4     H5     H6     Paragraph  Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\n   Blockquotes  The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\n   Blockquote without attribution   Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\n    Blockquote with attribution   Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\n    Tables  Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\n   Name Age     Bob 27   Alice 23       Inline Markdown within tables     Italics Bold Code     italics bold code       Code Blocks     Code block with backticks  1 2 3 4 5 6 7 8 9 10  \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;      Code block indented with four spaces  \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;     Code block with Hugo\u0026rsquo;s internal highlight shortcode  1 2 3 4 5 6 7 8 9 10  \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;      List Types     Ordered List   First item Second item Third item     Unordered List   List item Another item And another item     Nested list   Fruit  Apple Orange Banana   Dairy  Milk Cheese       Other Elements — abbr, sub, sup, kbd, mark  GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\n  The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n  ","date":"Mar 11","permalink":"https://srivendare.github.io/post/markdown-syntax/","tags":["markdown","css","html"],"title":"Markdown Syntax Guide"},{"categories":null,"contents":"   Nya nya nyan meow meow mama  More napping, more napping all the napping is exhausting stretch out on bed you are a captive audience while sitting on the toilet, pet me slap the dog because cats rule bleghbleghvomit my furball really tie the room together always hungry. Humans,humans, humans oh how much they love us felines we are the center of attention they feed, they clean miaow then turn around and show you my bum. Cats secretly make all the worlds muffins slap owner\u0026rsquo;s face at 5am until human fills food dish, milk the cow hunt by meowing loudly at 5am next to human slave food dispenser throwup on your pillow. Get scared by doggo also cucumerro .\n   Cat is meow meow  Sees bird in air, breaks into cage and attacks creature when in doubt, wash spend six hours per day washing, but still have a crusty butthole yet lick sellotape tickle my belly at your own peril i will pester for food when you\u0026rsquo;re in the kitchen even if it\u0026rsquo;s salad find box a little too small and curl up with fur hanging out.\nClaw at curtains stretch and yawn nibble on tuna ignore human bite human hand. Under the bed mice yet funny little cat chirrup noise shaking upright tail when standing next to you but white cat sleeps on a black shirt for eat an easter feather as if it were a bird then burp victoriously.\n   Has closed eyes but still sees you present belly  scratch hand when stroked for is good you understand your place in my world get scared by sudden appearance of cucumber. What the heck just happened, something feels fishy chew master\u0026rsquo;s slippers yet brown cats with pink ears bite the neighbor\u0026rsquo;s bratty kid cereal boxes make for five star accommodation but i like to spend my days sleeping and eating fishes that my human fished for me we live on a luxurious yacht, sailing proudly under the sun, i like to walk on the deck, watching the horizon, dreaming of a good bowl of milk. Lounge in doorway put butt in owner\u0026rsquo;s face, or ptracy destroy house in 5 seconds. Mrow no, you can\u0026rsquo;t close the door, i haven\u0026rsquo;t decided whether or not i wanna go out is good you understand your place in my world.\nBrown cats with pink ears shred all toilet paper and spread around the house being gorgeous with belly side up. Cats go for world domination the best thing in the universe is a cardboard box cats are cute so meow all night having their mate disturbing sleeping humans. Nya nya nyan annoy owner until he gives you food say meow repeatedly until belly rubs, feels good eat the fat cats food but meowing non stop for food. Pet right here, no not there, here, no fool, right here that other cat smells funny you should really give me all the treats because i smell the best and omg you finally got the right spot and i love you right now see brother cat receive pets, attack out of jealousy. Headbutt owner\u0026rsquo;s knee love blinks and purr purr purr purr yawn for stand in front of the computer screen, or mew mew for human is washing you why halp oh the horror flee scratch hiss bite.\n   Cats making all the muffins  Cats making all the muffins asdflkjaertvlkjasntvkjn (sits on keyboard) so the dog smells bad but cough hairball on conveniently placed pants and show belly but loved it, hated it, loved it, hated it catch mouse and gave it as a present. Give me attention or face the wrath of my claws meow all night for love me! and love you, then bite you or mesmerizing birds. Lick human with sandpaper tongue. Murf pratt ungow ungow scratch the box sit in box and to pet a cat, rub its belly, endure blood and agony, quietly weep, keep rubbing belly wake up human for food at 4am or eat owner\u0026rsquo;s food trip owner up in kitchen i want food. Curl up and sleep on the freshly laundered towels paw at your fat belly, steal mom\u0026rsquo;s crouton while she is in the bathroom yet nyan nyan goes the cat, scraaaaape scraaaape goes the walls when the cat murders them with its claws milk the cow suddenly go on wild-eyed crazy rampage toy mouse squeak roll over.\nHunt by meowing loudly at 5am next to human slave food dispenser hate dog reward the chosen human with a slow blink. Cat dog hate mouse eat string barf pillow no baths hate everything miaow then turn around and show you my bum love fish, and kitty scratches couch bad kitty steal the warm chair right after you get up kitty poochy munch on tasty moths. Take a big fluffing crap 💩 scratch at fleas, meow until belly rubs, hide behind curtain when vacuum cleaner is on scratch strangers and poo on owners food i rule on my back you rub my tummy i bite you hard.\nThanks by cats.\n","date":"Mar 09","permalink":"https://srivendare.github.io/post/example-lazy-load-image/","tags":["markdown","text","image"],"title":"Example Lazy Load Image"},{"categories":null,"contents":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\n Exierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude  Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\n Comas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et     Vagus elidunt  \nThe Van de Graaf Canon\n   Mane refeci capiebant unda mulcebat  Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"Mar 09","permalink":"https://srivendare.github.io/post/placeholder-text/","tags":["markdown","text"],"title":"Placeholder Text"},{"categories":null,"contents":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\n N.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3  .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; }  ","date":"Mar 05","permalink":"https://srivendare.github.io/post/emoji-support/","tags":["emoji"],"title":"Emoji Support"},{"categories":null,"contents":"","date":"Jan 01","permalink":"https://srivendare.github.io/articles/","tags":null,"title":"Archives"}]